{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tAb77yZ9fzMG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Activation, Dropout, UpSampling2D,Conv2D,MaxPooling2D,concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Activation,AveragePooling2D ,ReLU ,Add,Dense,Reshape,Multiply, Dropout, UpSampling2D,Conv2D,MaxPooling2D,concatenate,add,GlobalAveragePooling2D,GlobalMaxPool2D,Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import necessary items from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, UpSampling2D\n",
    "from keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images =np.load(\"D:/projects/Thesis/Dataset/D_img_512.npy\").astype(np.float32)\n",
    "labels = np.load(\"D:/projects/Thesis/Dataset/D_mask_512.npy\").astype(np.float32)\n",
    "train_images = np.array(train_images)\n",
    "labels = np.array(labels)\n",
    "labels = labels / 255\n",
    "train_images, labels = shuffle(train_images, labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.3)\n",
    "batch_size =2\n",
    "epochs = 200\n",
    "pool_size = (2, 2)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LKJ59bMzCN1o"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def dsc(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dsc(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "def IOU(y_true, y_pred):\n",
    "\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "\n",
    "    thresh = 0.5\n",
    "\n",
    "    y_true = K.cast(K.greater_equal(y_true, thresh), 'float32')\n",
    "    y_pred = K.cast(K.greater_equal(y_pred, thresh), 'float32')\n",
    "\n",
    "    union = K.sum(K.maximum(y_true, y_pred)) + K.epsilon()\n",
    "    intersection = K.sum(K.minimum(y_true, y_pred)) + K.epsilon()\n",
    "\n",
    "    iou = intersection/union\n",
    "\n",
    "    return iou\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16,VGG19,ResNet50\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, ZeroPadding2D\n",
    "def conv_block1(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def conv_block2(input, num_filters):\n",
    "    x = Conv2D(num_filters, 7, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "def deconv(x, kernelsize,fi):\n",
    "    #fi=x.shape[-1]\n",
    "    fx = Conv2DTranspose(fi, kernelsize, activation='relu', padding='same')(x)\n",
    "    fx = BatchNormalization()(fx)\n",
    "    fx =Conv2DTranspose(fi, kernelsize, padding='same')(fx)\n",
    "    out = BatchNormalization()(fx)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CECA(x1,x2,r):\n",
    "    \n",
    "    \n",
    "    f=x1.shape[-1]\n",
    "    x=concatenate([x1,x2], axis = 3)\n",
    "    a_pool = GlobalAveragePooling2D()(x)\n",
    "    m_pool = GlobalMaxPool2D()(x) \n",
    "    Dense_layer1 = Dense (f/r , activation = 'relu') \n",
    "    Dense_layer2 = Dense (f, activation = 'relu') \n",
    "    avg_out = Dense_layer2 (Dense_layer1(a_pool)) \n",
    "    max_out = Dense_layer2 (Dense_layer1( m_pool))\n",
    "    channel = add([ avg_out,max_out]) \n",
    "    channel = Activation('sigmoid') (channel) \n",
    "    channel = Reshape ((1,1,f)) (channel)  \n",
    "    C_out = Multiply()([x1,x2,channel])\n",
    "    return C_out\n",
    "    \n",
    "def GAM (il,ih):                     \n",
    "    ###### Spatial Attention ########\n",
    "    f=ih.shape[-1]\n",
    "    il =Conv2D(1,(3,3),strides=1,padding ='same') (il)\n",
    "    a_pool = GlobalAveragePooling2D()(ih)\n",
    "    m_pool = GlobalMaxPool2D()(ih) \n",
    "    Dense_layer1 = Dense (f , activation = 'relu') \n",
    "    Dense_layer2 = Dense (f, activation = 'relu') \n",
    "    avg_out = Dense_layer2 (Dense_layer1(a_pool)) \n",
    "    max_out = Dense_layer2 (Dense_layer1( m_pool))\n",
    "    channel = add([ avg_out,max_out]) \n",
    "    channel = Activation('sigmoid') (channel) \n",
    "    channel = Multiply()([il,channel])\n",
    "    s=add([ channel,ih]) \n",
    "    \n",
    "    av_pooling=AveragePooling2D(pool_size=(1,1))(s)\n",
    "    ma_pooling=MaxPooling2D(pool_size=(1,1))(s)\n",
    "    spatial=concatenate([av_pooling,ma_pooling], axis = 3)\n",
    "    spatial =Conv2D(1,(7,7),strides=1,padding ='same') (spatial) \n",
    "    \n",
    "    \n",
    "    spatial= Activation('sigmoid')(spatial)\n",
    "      \n",
    "    S_out = Multiply()([s,spatial])\n",
    "    \n",
    "    return S_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AFM(i1,i2):\n",
    "    \n",
    "    x = Concatenate()([i1,i2])\n",
    "    \n",
    "    m_pool = MaxPooling2D(pool_size=(1,1))(x)\n",
    "    \n",
    "    w =Conv2D(1,(3,3),strides=1,padding ='same') (m_pool) \n",
    "    w= Activation('sigmoid')(w)\n",
    "    I=Multiply()([i1,w])\n",
    "    J= Concatenate()([i2, I])\n",
    "    \n",
    "    return J\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "inputs = keras.layers.Input((512,512,3))\n",
    "\n",
    "\n",
    "\"\"\" Encoder \"\"\"\n",
    "s1 = conv_block1(inputs,16)  \n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(s1)\n",
    "s2 = conv_block2(inputs,16) \n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(s2)\n",
    "E1=CECA(pool1,pool2,8)\n",
    "\n",
    "\n",
    "s3 = conv_block1(pool1,16) \n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(s3)\n",
    "s4= conv_block2(pool2,16) \n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(s4)\n",
    "E2=CECA(pool3,pool4,8)\n",
    "\n",
    "\n",
    "\n",
    "s5 = conv_block1(pool3,32)  \n",
    "pool5 = MaxPooling2D(pool_size=(2, 2))(s5)\n",
    "s6= conv_block2(pool3,32) \n",
    "pool6 = MaxPooling2D(pool_size=(2, 2))(s6)\n",
    "E3=CECA(pool5,pool6,8)\n",
    "\n",
    "\n",
    "s7 = conv_block1(pool5,64) \n",
    "pool7 = MaxPooling2D(pool_size=(2, 2))(s7)\n",
    "s8= conv_block2(pool6,64)  \n",
    "pool8 = MaxPooling2D(pool_size=(2, 2))(s8)\n",
    "E4=CECA(pool7,pool8,8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s9 = conv_block1(pool7,128) \n",
    "pool9 = MaxPooling2D(pool_size=(2, 2))(s9)\n",
    "s10= conv_block2(pool8,128)  \n",
    "pool10 = MaxPooling2D(pool_size=(2, 2))(s10)\n",
    "E5=CECA(pool9,pool10,8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "E5=UpSampling2D(size = (2,2))(E5)\n",
    "D1=GAM(E5,E4)\n",
    "D1=deconv(D1, 3,128)\n",
    "\n",
    "\n",
    "D2=UpSampling2D(size = (2,2))(D1)\n",
    "D2=GAM(D2,E3)\n",
    "D2=deconv(D2, 3,64)\n",
    "\n",
    "\n",
    "D3=UpSampling2D(size = (2,2))(D2)\n",
    "D3=GAM(D3,E2)\n",
    "D3=deconv(D3, 3,32)\n",
    "\n",
    "D4=UpSampling2D(size = (2,2))(D3)\n",
    "D4=GAM(D4,E1)\n",
    "D4=deconv(D4, 3,16)\n",
    "\n",
    "D5=UpSampling2D(size = (2,2))(D4)\n",
    "\n",
    "D5=deconv(D5, 3,16)\n",
    "\n",
    "############ Decoder #############\n",
    "\n",
    "\"\"\" Outputs \"\"\"\n",
    "outputs = Conv2D(3, 1, padding=\"same\", activation=\"sigmoid\")(D5)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "    \n",
    "\n",
    "datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=opt,  loss = dice_loss, metrics = ['dsc','accuracy', 'IOU','precision_m', 'recall_m', 'f1_m'])\n",
    "model.summary()\n",
    "\n",
    "###### Saving the model ############\n",
    "model.save('D:/projects/Thesis/Thesis_final_7.h5')\n",
    " \n",
    "# load model\n",
    "model = load_model('D:/projects/Thesis/Thesis_final_7.h5',custom_objects={'dice_loss':dice_loss,'IOU':IOU,'dsc':dsc,'precision_m':precision_m, 'recall_m':recall_m, 'f1_m':f1_m})\n",
    "history=model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,\n",
    "epochs=200, verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "model.save('D:/projects/Thesis/Thesis_final_7.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "U-net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
